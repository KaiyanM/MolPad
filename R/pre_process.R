#' Pre-processing datasets
#'
#' @description The `pre_process()` function aids in processing data inputs and automatically establishes a standardized format for future use. It allows for two types of data input: a list of datasets from different sources or a long dataset containing a specified column `type`. It's important to note that for each dataset, the initial column is designated for `ID`s, while the subsequent columns are expected to contain values measured on Time1, Time2, and so forth.
#' @docType package
#' @name pre_process
#'
#' @param data A data.frame to describe each feature in one row. The data should contain variables \code{ID}, \code{value on time_1}, ..., \code{value on time_k}, and \code{type} for extracting patterns across the time. 
#' If multiple data.frame with the above format needs to be analyzed, you could also put a list of data.frame into this argument. 
#' In this case, variable \code{type} is not required and will be generated by the next argument \code{typenameList}.
#' @param typenameList A vector of strings. This parameter is used to clarify the source or names for each data.frame, and is only applicable when the input of \code{data} is a list of data.frame. By default, it will be set as "Dataset_1", "Dataset_2", ..., etc.
#' @param replaceNa Logical; if `replaceNa` is TRUE (default), replace NA with 0.
#' @param scale Logical; if `scale` is TRUE (default), standardize the data.frame by row with \code{base::scale}. This converts each original value into a z-score. See also `scale_by_row__()`.
#' @param autoColName A string; if `autoColName` is not-NULL (default), it will automatically set uniform column names for all the data.frames. 
#' This parameter is only applicable when the input of \code{data} is a list of data.frame.
#'
#' @details
#' We consider two distinct scenarios for this application:
#' 
#' * In one scenario, individuals collect several datasets from various aspects and instruments for the same objects. For example, they might be separately detecting lipids, metabolites, and peptides from a specific soil sample.
#' 
#' * In the other scenario, all the data is of uniform quality, but it can be categorized into larger groups that exhibit significant differences.
#' In both of these cases, the pre_process() function serves as a valuable and versatile tool. Yet, this function is optional when generating the dashboard. Users can perform their own processing as long as the format matches the required output. However, they should be mindful that the number of samples (timepoints) must be greater than 5 to avoid potential errors in the subsequent prediction section.
#' 
#' @returns The function returns A long data.frame with columns \code{ID}, \code{value on time_1}, ..., \code{value on time_k}, and \code{type}.
#' 
#' @examples
#' data(test_data)
#' head(test_data, 10)
#' a <- pre_process(test_data)
#' head(a, 10)
#' 
#' @importFrom dplyr bind_rows
#' @export
pre_process <- function(data, typenameList = NULL, replaceNA = TRUE,
                        scale = TRUE, autoColName = "Sec_") {
  if(is.data.frame(data)==FALSE){
    print("Reformat a list of datasets:")
    # set default type names
    if (is.null(typenameList)==FALSE) {
      typenameList <- paste0("Dataset_", seq_along(data))
    }
    for (i in seq_along(data)) {
      # set uniform column names
      if (is.null(autoColName)) {
        colnames(data[[i]]) <- c("ID", paste0(autoColName, 1:(ncol(data[[i]]) - 1)))
      }
      # replace NA with 0
      if (replaceNA) {
        data[[i]][is.na(data[[i]])] <- 0
      }
      # scale by feature (by row)
      if (scale) {
        data[[i]] <- scale_by_row__(data[[i]])
      }
      # add type name to corresponding data
      data[[i]]$type <- rep(typenameList[i], nrow(data[[i]]))
    }
    
    data <- data |>
      bind_rows() |>
      mutate(ID = as.factor(ID))
    

  }
  
  else{
    data$type[is.na(data$type)] <- "Other"
    if (replaceNA) {
      data[is.na(data)] <- 0
    }
    if(scale){
      data <- scale_by_row__(data) |> na.omit()
    }
  }
  
  return(data)
}
